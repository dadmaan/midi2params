{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook turned from a replication of the colab demo to a more general data exploration notebook for the synthesized and real wav files, as well as their audio parameter extractions from DDSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_twinkle(base=500, length=1250):\n",
    "    # returns twinkle in f0\n",
    "\n",
    "    Msec = 1.1224653607\n",
    "    Mthird = 1.259913999\n",
    "    fourth = 1.3348494983\n",
    "    fifth = 1.4983086479\n",
    "    Msixth = 1.6817964644\n",
    "    arrs = [np.linspace(base, base, 50),  # B\n",
    "            np.linspace(base, base, 50),  # B\n",
    "            np.linspace(base*fifth, base*fifth, 50),  # F#\n",
    "            np.linspace(base*fifth, base*fifth, 50),  # F#\n",
    "            np.linspace(base*Msixth, base*Msixth, 50),  # G#\n",
    "            np.linspace(base*Msixth, base*Msixth, 50),  # G#\n",
    "            np.linspace(base*fifth, base*fifth, 100),  # F#\n",
    "            np.linspace(base*fourth, base*fourth, 50),  # E\n",
    "            np.linspace(base*fourth, base*fourth, 50),  # E\n",
    "            np.linspace(base*Mthird, base*Mthird, 50),  # D#\n",
    "            np.linspace(base*Mthird, base*Mthird, 50),  # D#\n",
    "            np.linspace(base*Msec, base*Msec, 50),  # C#\n",
    "            np.linspace(base*Msec, base*Msec, 50),  # C#\n",
    "            np.linspace(base, base, 100),  # B\n",
    "    ]\n",
    "\n",
    "\n",
    "    f0 = np.concatenate((arrs))\n",
    "\n",
    "    return np.concatenate((f0, np.linspace(base, base, length - f0.shape[0]))), f0.shape[0]\n",
    "\n",
    "def generate_loud(length=1250, decay=True):\n",
    "    beats = [0, 50, 100, 150, 200, 250, 300, 400, 450, 500, 550, 600, 650, 700, 800]\n",
    "    arrs = []\n",
    "    base = -50\n",
    "    decay_rate = -0.25 # decays -1 per timestep/index\n",
    "    notelength = 0.7\n",
    "    for i, beat in enumerate(beats):\n",
    "        if i == len(beats) - 1:\n",
    "            arr = np.linspace(-100, -100, length - beat)\n",
    "        else:\n",
    "            next_beat = beats[i + 1]\n",
    "            if decay:\n",
    "                arr = np.linspace(base, base + decay_rate * (next_beat - beat), next_beat - beat)\n",
    "            else:\n",
    "                notelengthidx = int(notelength * (next_beat - beat))\n",
    "                restlengthidx = (next_beat - beat) - notelengthidx\n",
    "                l = [np.linspace(base, base, notelengthidx),\n",
    "                     np.linspace(-100, -100, restlengthidx)]\n",
    "                arr = np.concatenate(l)\n",
    "        arrs.append(arr)\n",
    "    return np.concatenate(arrs)\n",
    "    \n",
    "# in the notebook\n",
    "f0_hz, stopidx = generate_twinkle()\n",
    "loudness_db = generate_loud(decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness_db = np.concatenate((-40 * np.ones(800), -100 * np.ones(450)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(f0_hz)\n",
    "plt.title('Fundamental Frequency (No Heuristic Modification)')\n",
    "plt.figure()\n",
    "plt.title('Loudness (Partial Heuristic Modification)')\n",
    "plt.plot(loudness_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_URL_OR_FP = '/juice/scr/rjcaste/curis/wavegenie/notebooks/20af160e2b6d96f89016425f2e776910-35.wav'\n",
    "START_TIME = 0\n",
    "END_TIME = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio\n",
    "\n",
    "from wavegenie.audio_io import load_audio, save_wav\n",
    "from wavegenie.util import preview_audio, DDSP_DEFAULT_FS_AUDIO\n",
    "\n",
    "audio, fs = load_audio(\n",
    "    AUDIO_URL_OR_FP,\n",
    "    DDSP_DEFAULT_FS_AUDIO,\n",
    "    num_channels=1,\n",
    "    normalize=True,\n",
    "    start_time_seconds=START_TIME,\n",
    "    end_time_seconds=END_TIME)\n",
    "\n",
    "#preview_audio(audio)\n",
    "#save_wav('input_16k_mono_f32.wav', audio, DDSP_DEFAULT_FS_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract synthesis parameters\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wavegenie.util import extract_ddsp_synthesis_parameters\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "audio_parameters = extract_ddsp_synthesis_parameters(audio)\n",
    "print('took {:.3g} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wavegenie.viz_utils import standard_plot, alt_plot, get_percent\n",
    "def alt_plot(audio_parameters, shade_param=None, cutoff_percentile=0.5, plot_freqs=False, waveform=None):\n",
    "    # plot with extra stuff (overlays, etc.)\n",
    "    # audio_parameters: the audio parameters obtained from before\n",
    "    # shade_param: the parameter potentially used to shade the graph vertically\n",
    "    # cutoff_percentile: percentile to cutoff the shading for shade_param\n",
    "    # plot_freqs: plot musical note frequencies as horizontal lines on the plot\n",
    "    # waveform: if audio provided, plot it\n",
    "    \n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.plot(np.linspace(0, 2.4, audio_parameters['f0_hz'].shape[0]), audio_parameters['f0_hz'], label='f0')\n",
    "    if not(shade_param is None):\n",
    "        # if -1, use smooth shading, otherwise use percentile\n",
    "        if cutoff_percentile == -1:\n",
    "            max_, min_ = audio_parameters[shade_param].max(), audio_parameters[shade_param].min()\n",
    "            for i, param in enumerate(audio_parameters[shade_param]):\n",
    "                plt.axvspan(i, i + 1, alpha=(param - min_) / (2 * (max_ - min_)))\n",
    "        else:\n",
    "            cutoff = get_percent(audio_parameters[shade_param], cutoff_percentile)\n",
    "            for region in contiguous_regions(audio_parameters[shade_param] > cutoff):\n",
    "                plt.axvspan(region[0], region[1], alpha=0.3)\n",
    "\n",
    "    title = 'f0 Hz'\n",
    "    if not(shade_param is None):\n",
    "        title += ', shaded by {} ({})'.format(shade_param, 'smoothly' if cutoff_percentile==-1 else cutoff_percentile)\n",
    "    plt.title(title)\n",
    "\n",
    "    # extra waveform ontop\n",
    "    if not(waveform is None):\n",
    "        # skipping over 63 elements since waveform is sampled 64x\n",
    "        # compared to the audio parameters\n",
    "        plt.plot(np.linspace(0, 2.4, waveform.flatten()[::64].shape[0]), 100 * waveform.flatten()[::64] + get_percent(audio_parameters['f0_hz'], 0.1),\n",
    "                 label='waveform')\n",
    "    \n",
    "    # extra frequency horizontal lines\n",
    "    if plot_freqs:\n",
    "        frequencies = {'_A': 220,\n",
    "                       '_B': 246,\n",
    "                       '_C': 261,\n",
    "                       '_D': 293,\n",
    "                       '_E': 329,\n",
    "                       '_F': 349,\n",
    "                       '_G': 392,\n",
    "                       'A': 440,\n",
    "                       'B': 493,\n",
    "                       'C': 523,\n",
    "                       'D': 587,\n",
    "                       'D#': 622,\n",
    "                       'E': 659,\n",
    "                       'F': 698,\n",
    "                       'F#': 740,\n",
    "                       'G': 784,\n",
    "                       'A_': 880}\n",
    "        for note, f in frequencies.items():\n",
    "            plt.plot(f * np.ones(1300), label='{}{}'.format(note, f))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.plot(np.linspace(0, 2.4, audio_parameters['loudness_db'].shape[0]), audio_parameters['loudness_db'])\n",
    "    plt.plot(np.linspace(0, 2.4, waveform.flatten()[::64].shape[0]), 100 * waveform.flatten()[::64] + get_percent(audio_parameters['loudness_db'], 0.1),\n",
    "                 label='waveform')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.plot(audio_parameters['f0_confidence'])\n",
    "    plt.show()\n",
    "alt_plot(audio_parameters, waveform=resynth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wavegenie.util import standard_plot, alt_plot\n",
    "\n",
    "alt_plot(audio_parameters, plot_freqs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "from wavegenie.util import load_ddsp_model\n",
    "\n",
    "model = load_ddsp_model('Violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_parameters = {}\n",
    "audio_parameters['f0_hz'] = f0_hz.astype('float32')\n",
    "audio_parameters['loudness_db'] = loudness_db.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resynthesize parameters\n",
    "\n",
    "from wavegenie.util import synthesize_ddsp_audio\n",
    "from wavegenie.util import preview_audio\n",
    "\n",
    "resynth = synthesize_ddsp_audio(model, audio_parameters)\n",
    "\n",
    "preview_audio(resynth)\n",
    "save_wav('output_16k_mono_f32.wav', resynth, DDSP_DEFAULT_FS_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resynthesize parameters\n",
    "\n",
    "from wavegenie.util import synthesize_ddsp_audio\n",
    "\n",
    "reresynth = synthesize_ddsp_audio(model, audio_parameters)\n",
    "\n",
    "preview_audio(reresynth)\n",
    "save_wav('output_16k_mono_f32.wav', resynth, DDSP_DEFAULT_FS_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resynthesize parameters\n",
    "\n",
    "from wavegenie.util import synthesize_ddsp_audio\n",
    "\n",
    "reresynth = synthesize_ddsp_audio(model, audio_parameters)\n",
    "\n",
    "preview_audio(reresynth)\n",
    "save_wav('output_16k_mono_f32.wav', resynth, DDSP_DEFAULT_FS_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
