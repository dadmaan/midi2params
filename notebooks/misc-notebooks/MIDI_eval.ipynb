{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to test out the `mir_eval` functionality on heuristically-converted MIDI vs. ground truth MIDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import mir_eval\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write as wavwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below to the \"debug\" section is intended to be run consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpath = '/juice/scr/rjcaste/curis/wavegenie/data/CustomViolin_params2midi_dev/heuristic_midis/elvis.p'\n",
    "hpath = '../data/CustomViolin_16k/midi/val/elvis.mid'\n",
    "groundtruth_path = '/juice/scr/rjcaste/curis/wavegenie/data/CustomViolin_params2midi_dev/midi/elvis.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_midi = pretty_midi.PrettyMIDI(groundtruth_path)\n",
    "#hmidi = pickle.load(open(hpath, 'rb'))\n",
    "hmidi = pretty_midi.PrettyMIDI(hpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi2_ip(notes):\n",
    "    \"\"\"\n",
    "    Converts notes list (from pretty_midi) to intervals and pitches.\n",
    "    \"\"\"\n",
    "    \n",
    "    onsets = np.array([n.start for n in notes])\n",
    "    offsets = np.array([n.end for n in notes])\n",
    "    pitches = np.array([n.pitch for n in notes])\n",
    "    intervals = np.vstack((onsets, offsets)).T\n",
    "    \n",
    "    return intervals, pitches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get estimated intervals and pitches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitches, onsets, offsets = hmidi['pitches'], hmidi['onsets_sec'], hmidi['offsets_sec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#est_pitches = np.array(pitches, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#est_intervals = np.vstack((onsets, offsets)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_intervals, est_pitches = midi2_ip(hmidi.instruments[0].notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ground truth intervals and pitches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_intervals, ref_pitches = midi2_ip(gt_midi.instruments[0].notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mir_eval.transcription.evaluate(ref_intervals, ref_pitches, est_intervals, est_pitches, onset_tolerance=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mir_eval.transcription.evaluate(ref_intervals, ref_pitches, est_intervals, np.array([int(round(p)) for p in est_pitches]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthesize\n",
    "midi = pretty_midi.PrettyMIDI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin = pretty_midi.Instrument(program=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin.notes = [pretty_midi.Note(velocity=100, pitch=int(round(p)), start=i[0], end=i[1]) for i, p in zip(est_intervals, est_pitches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin.notes = violin.notes[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi.instruments = [violin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = midi.fluidsynth(fs=16000)\n",
    "out_gt = gt_midi.fluidsynth(fs=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wavegenie.util import preview_audio, DDSP_DEFAULT_FS_AUDIO\n",
    "start_time = 20\n",
    "end_time = 25\n",
    "start_idx = 16000*start_time\n",
    "end_idx = 16000*end_time\n",
    "audio = np.stack((out[start_idx:end_idx], out_gt[start_idx:end_idx])).T\n",
    "preview_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_audio(np.stack((out[16000*start_time:16000*end_time], out[16000*start_time + 100:16000*end_time + 100])).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi.instruments[0].program = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_audio = midi.fluidsynth(fs=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavwrite('heuristic.wav', 16000, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_audio = gt_midi.fluidsynth(fs=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = np.stack((est_audio[:3034471], ref_audio)).T.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavwrite('heuristic.wav', 16000, both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddsp-rod",
   "language": "python",
   "name": "ddsp-rod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
