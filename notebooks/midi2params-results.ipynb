{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Evaluation of midi2params\n",
    "Notebook to qualitatively evaluate our trained midi2params model. This has a lot of extra details and is not *that* user-friendly, so be warned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line basically \"injects\" the global state of this script\n",
    "# at the end into this notebook\n",
    "%run ../midi2params/interact.py\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's first get our batch and see what's in it. Here you can choose which example we want to look at (with `i`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, play the original audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util import preview_audio\n",
    "\n",
    "audio = to_numpy(batch['audio'][i])[..., np.newaxis]\n",
    "preview_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, 5, audio.flatten().shape[0]), audio.flatten())\n",
    "plt.yticks([])\n",
    "plt.title('Audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesized from features extracted with DDSP\n",
    "Now, synthesize with DDSP from the features extracted with DDSP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract synthesis parameters\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.util import extract_ddsp_synthesis_parameters\n",
    "\n",
    "audio_parameters = extract_ddsp_synthesis_parameters(audio)\n",
    "\n",
    "plt.title('f0(t)')\n",
    "plt.plot(audio_parameters['f0_hz'], color='orange')\n",
    "plt.xlim(0, 1250)\n",
    "plt.show()\n",
    "plt.title('l(t)')\n",
    "plt.plot(audio_parameters['loudness_db'])\n",
    "plt.xlim(0, 1250)\n",
    "plt.ylim(-120, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda x: (x - x.min()) / (x.max() - x.min())\n",
    "plt.figure(figsize=(16, 4))\n",
    "N = len(batch['pitches'][i][100:])\n",
    "plt.scatter(np.linspace(0, 5, N), normalize(batch['pitches'][i][100:]), s=2)\n",
    "#plt.plot(normalize(audio_parameters['f0_hz']))\n",
    "plt.xlim(0, 5)\n",
    "plt.yticks([])\n",
    "plt.title('MIDI Piano Roll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "from utils.util import load_ddsp_model\n",
    "\n",
    "#model = load_ddsp_model('Violin')\n",
    "ckpt_path = '../checkpoints/CustomViolinCheckpoint'\n",
    "model = load_ddsp_model(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resynthesize parameters\n",
    "\n",
    "from utils.util import synthesize_ddsp_audio\n",
    "\n",
    "resynth = synthesize_ddsp_audio(model, audio_parameters)\n",
    "\n",
    "preview_audio(resynth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesize with *heuristically generated* features from MIDI\n",
    "Now, synthesize with DDSP from the features *heuristically generated* from associated MIDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loud(beats, length=1250, decay=True):\n",
    "    arrs = []\n",
    "    length = 2500\n",
    "    base = -30\n",
    "    decay_rate = -0.01 # decays -1 per timestep/index\n",
    "    #notelength = 0.7\n",
    "    ld_arr = np.full((length), -120)\n",
    "    for i, beat in enumerate(beats):\n",
    "        if i == len(beats) - 1:\n",
    "            next_beat = length\n",
    "        else:\n",
    "            next_beat = beats[i + 1]\n",
    "        ld_arr[beat:next_beat] = np.linspace(base, base + decay_rate * (next_beat - beat), next_beat - beat)\n",
    "\n",
    "    return ld_arr\n",
    "\n",
    "\n",
    "def gen_heuristic(batch, i=0):\n",
    "    \"\"\"\n",
    "    Take a batch containing 'pitches', 'onset_arr', and 'offset_arr' and\n",
    "    turn them into f0 and loudness heuristically.\n",
    "    \"\"\"\n",
    "    onsets = np.where(batch['onset_arr'][i] == 1)[0]\n",
    "    if len([i for i in onsets if i < 30]) == 0:\n",
    "        onsets = np.concatenate(([10], onsets))\n",
    "\n",
    "    ld = generate_loud(onsets)\n",
    "    pitches = copy.deepcopy(batch['pitches'][i])\n",
    "    f0 = p2f(pitches)\n",
    "    return f0, ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_h, ld_h = gen_heuristic(batch, i=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('f0(t)')\n",
    "f0_h_sin = np.abs(np.array(f0_h) + 3 * np.sin(np.arange(2500) * .15))\n",
    "plt.plot(f0_h, color='orange')\n",
    "plt.plot(f0_h_sin, color='red')\n",
    "plt.xlim(0, 1250)\n",
    "plt.show()\n",
    "plt.title('l(t)')\n",
    "plt.plot(audio_parameters['loudness_db'], label='loudness (ground truth)')\n",
    "plt.plot(ld_h, label='loudness (generated)')\n",
    "plt.ylim(-120, 0)\n",
    "plt.xlim(0, 1250)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_f0_h_sin = torch.FloatTensor(f0_h_sin)\n",
    "#torch_f0_h_sin.dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heuristic_parameters = {\n",
    "    'f0_hz': torch_f0_h_sin.type(torch.float32),\n",
    "    'loudness_db': ld_h.astype(np.float32)\n",
    "}\n",
    "params = heuristic_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resynthesize parameters\n",
    "\n",
    "from utils.util import synthesize_ddsp_audio\n",
    "\n",
    "heuristic_resynth = synthesize_ddsp_audio(model, params)\n",
    "\n",
    "preview_audio(heuristic_resynth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesize from feature outputs from *learned model*\n",
    "Now, synthesize with DDSP from the features generated from the associated MIDI *with our trained model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../model/best_model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model and generate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_best_model(config, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.device == 'cuda':\n",
    "    for k, arr in batch.items():\n",
    "        batch[k] = torch.Tensor(arr.float()).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_pred, ld_pred = midi2params(best_model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, arr in batch.items():\n",
    "    batch[k] = to_numpy(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)\n",
    "f0 = batch['f0'][i]\n",
    "ld = batch['loudness_db'][i]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('f0(t) comparison')\n",
    "plt.plot(f0_pred[i], label='f0 (generated)')\n",
    "plt.plot(f0, alpha=0.5, label='f0 (ground truth)')\n",
    "plt.xlim(0, 1250)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('l(t)')\n",
    "plt.plot(ld_pred[i], label='loudness (generated)')\n",
    "plt.plot(ld, alpha=0.5, label='loudness (ground truth)')\n",
    "plt.xlim(0, 1250)\n",
    "plt.ylim(-120, 0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'f0_hz': f0_pred[i],\n",
    "    'loudness_db': ld_pred[i]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resynthesize parameters\n",
    "\n",
    "from utils.util import synthesize_ddsp_audio, preview_audio\n",
    "\n",
    "new_model_resynth = synthesize_ddsp_audio(model, train_params)\n",
    "\n",
    "preview_audio(new_model_resynth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, all of them side-by-side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_audio(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct DDSP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_audio(resynth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristically Generated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_audio(heuristic_resynth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features from Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_audio(new_model_resynth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv3",
   "language": "python",
   "name": "testenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
